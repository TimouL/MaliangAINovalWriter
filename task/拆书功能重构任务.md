# 拆书功能重构任务

**创建日期：** 2025-11-30  
**最后更新：** 2025-11-30  
**状态：** 进行中  
**优先级：** 高  
**关联文档：** `task/拆书重构任务专家点评.md`

---

## 一、重构目标与原则

### 1.1 重构终极目标

1. **省钱** - 合并 Prompt 请求，降低 Token 成本（当前成本是理论值的 6-8 倍）
2. **好用** - 修复向量化链路，支持全本分析，优化交互体验
3. **智能** - 利用拆书产物赋能 Agent，实现高水平的仿写和续写

### 1.2 核心原则

- **Token 成本优先** - 任何架构决策都要考虑 Token 消耗
- **灵活的批次控制** - 基于 Token 数量而非章节数量分批，适配不同模型的上下文窗口
- **不截断章节** - 保持章节完整性，宁可少发一章也不截断
- **系统联动** - 保持与 LLM 可观测模块、计费模块等的正常集成
- **功能完整** - 补全当前缺失的提取功能
- **输出可控** - 考虑模型 Output Token 限制，合理分组请求

---

## 二、当前架构分析

### 2.1 功能概述

拆书功能用于从番茄小说或用户导入的文本中提取知识（设定、人物、情节等），生成结构化的知识库供后续创作参考。

### 2.2 核心组件

| 组件 | 职责 | 文件位置 |
|------|------|----------|
| `KnowledgeExtractionService` | 对外服务接口 | `service/KnowledgeExtractionService.java` |
| `KnowledgeExtractionServiceImpl` | 服务实现 | `service/impl/KnowledgeExtractionServiceImpl.java` |
| `KnowledgeExtractionTaskExecutor` | 主任务执行器 | `task/executor/KnowledgeExtractionTaskExecutor.java` |
| `KnowledgeExtractionGroupTaskExecutor` | 子任务执行器 | `task/executor/KnowledgeExtractionGroupTaskExecutor.java` |
| `KnowledgeExtractionStrategy` | AI 提取策略 | `service/ai/strategy/KnowledgeExtractionStrategy.java` |
| `IndexingService` | 向量索引服务 | `service/IndexingService.java` |
| `LLMTraceService` | LLM 可观测服务 | `service/ai/observability/LLMTraceService.java` |

### 2.3 数据模型

| 模型 | 用途 |
|------|------|
| `FanqieNovelImportRecord` | 导入记录 |
| `KnowledgeExtractionTaskRecord` | 任务详情记录 |
| `BackgroundTask` | 通用后台任务 |
| `NovelKnowledgeBase` | 知识库结果 |
| `LLMTrace` | LLM 调用追踪 |

### 2.4 提取类型与 UI 展示

| 组名 | 提取类型 | UI Tab | 实现状态 |
|------|---------|--------|---------|
| 文风叙事 | NARRATIVE_STYLE, WRITING_STYLE, WORD_USAGE | 文风叙事 | ✅ 已实现 |
| 情节设计 | CORE_CONFLICT, SUSPENSE_DESIGN, STORY_PACING | 情节设计 | ✅ 已实现 |
| 人物塑造 | CHARACTER_BUILDING | 人物塑造 | ✅ 已实现 |
| 小说特点 | WORLDVIEW, GOLDEN_FINGER | 小说特点 | ✅ 已实现 |
| 读者情绪 | RESONANCE, PLEASURE_POINT, EXCITEMENT_POINT | 读者情绪 | ✅ 已实现 |
| 热梗搞笑点 | HOT_MEMES, FUNNY_POINTS | 热梗搞笑点 | ✅ 已实现 |
| 用户自定义 | CUSTOM | 用户自定义 | ⚠️ 未完善 |
| 章节大纲 | CHAPTER_OUTLINE | 章节大纲 | ✅ 已实现 |

### 2.5 系统联动关系

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              拆书功能核心                                     │
└─────────────────────────────────────────────────────────────────────────────┘
        │                    │                    │                    │
        ▼                    ▼                    ▼                    ▼
┌──────────────┐    ┌──────────────┐    ┌──────────────┐    ┌──────────────┐
│ LLM 可观测    │    │ 计费系统      │    │ 向量存储      │    │ 任务管理      │
│              │    │              │    │ (Chroma)     │    │              │
│ - LLMTrace   │    │ - TokenUsage │    │ - Embedding  │    │ - Background │
│ - 调用统计    │    │ - 成本核算    │    │ - RAG 检索   │    │   Task       │
│ - 性能监控    │    │ - 用户配额    │    │              │    │ - 进度追踪    │
└──────────────┘    └──────────────┘    └──────────────┘    └──────────────┘
        │                    │                    │                    │
        └────────────────────┴────────────────────┴────────────────────┘
                                      │
                                      ▼
                    ┌──────────────────────────────┐
                    │ 后台管理 UI                   │
                    │ - LLM 可观测看板              │
                    │ - 任务管理看板                │
                    │ - 成本审计                   │
                    └──────────────────────────────┘
```

---

## 三、已识别的缺陷清单

### 3.1 阻断级缺陷 (P0)

#### 🔴 缺陷1：Token 成本结构失控（商业阻断）

**现状：**
- 系统将同一本小说全文重复发送给 LLM 6-8 次（按组分别请求）
- 每次调用 `extractKnowledgeForGroup()` 都发送完整的 `content`

**代码位置：**
```java
// KnowledgeExtractionStrategy.java
public Mono<List<NovelSettingItem>> extractKnowledgeForGroup(
        List<KnowledgeExtractionType> types,
        String content,  // ← 每次都发送完整内容
        ...
)
```

**影响：**
- 5 万字小说，理论消耗 ~7 万 tokens
- 实际消耗 = 7 万 × 7 组 = **49 万 tokens**（7 倍成本）

**修复方案：**
- 实施 **Single-Pass** 策略：一次 LLM 调用提取所有维度
- 或 **Map-Reduce**：先摘要后分析

---

#### ✅ 缺陷2：向量化链路断裂（功能阻断）【已修复】

**原问题：**
```java
// KnowledgeExtractionTaskExecutor.java
return sceneRepository.save(scene)  // ← 直接写库，跳过向量化
```

**问题：** 绕过 Service 层，未调用 `IndexingService.indexScene()`

**影响：**
- Chroma 向量库为空
- RAG 功能（智能问答、风格模仿）完全失效

**修复方案：**
```java
// 修复后
return sceneRepository.save(scene)
        .flatMap(saved -> indexingService.indexScene(saved).thenReturn(saved))
```

**✅ 修复状态：已完成**
- 修复日期：2025-11-30
- 修复文件：`task/executor/KnowledgeExtractionTaskExecutor.java`
- 修复内容：
  1. 添加 `IndexingService` 依赖注入
  2. 在 `createScenesForChapters()` 方法中，Scene 保存后立即调用 `indexingService.indexScene()`
  3. 向量化失败时记录警告日志但不阻断主流程（容错处理）
- 修复代码：
```java
return sceneRepository.save(scene)
        .flatMap(savedScene -> {
            // ✅ 修复向量化链路：保存后立即索引到Chroma向量库
            return indexingService.indexScene(savedScene)
                    .doOnSuccess(v -> log.info("✅ Scene向量化成功: {}", savedScene.getTitle()))
                    .doOnError(e -> log.warn("⚠️ Scene向量化失败(不影响主流程): {}, error={}", 
                            savedScene.getTitle(), e.getMessage()))
                    .onErrorResume(e -> Mono.empty()) // 向量化失败不阻断主流程
                    .thenReturn(savedScene);
        })
        .flatMap(savedScene -> {
            // 更新Chapter的sceneIds
            // ...
        });
```

---

#### 🔴 缺陷3：全书分析能力缺失（产品阻断）

**现状：**
```java
// KnowledgeExtractionTaskExecutor.java
return Flux.fromIterable(chapterList.getChapters())
        .take(10)  // ← 硬编码只取前 10 章
```

**影响：**
- 300 章小说只分析前 10 章（3.3%）
- 无法分析剧情走向、伏笔回收、人物成长

**修复方案：**
- 移除 `take(10)` 硬编码
- 引入 **基于 Token 的智能分批**（见下文详细设计）

---

### 3.2 严重缺陷 (P1)

#### 🟠 缺陷4：缺乏 Token 成本熔断机制

**现状：** 无任何成本控制机制

**风险：** 异常长文可能消耗大量 Token，烧穿预算

**修复方案：**
- Stage 执行前检查累计 Token
- 超过阈值（如 10 元）自动熔断并通知用户

---

#### 🟠 缺陷5：章节分批策略不合理

**现状：** 基于章节数量（`take(10)`）分批

**问题：**
- 不同章节长度差异大（短篇 2000 字，长篇 8000 字）
- 不同模型上下文窗口不同（4K ~ 128K）
- 可能截断章节或浪费上下文空间

**修复方案：**
- 基于 **Token 数量** 动态分批
- 保持章节完整性（宁可少发一章）
- 根据模型配置自动调整批次大小

---

### 3.3 中等缺陷 (P2)

#### 🟡 缺陷6：子任务轮询机制低效 ✅ 已修复

**状态：** 已在提交 `e30cf1d` 中修复，改为事件驱动

---

#### 🟡 缺陷7：父子任务架构过度设计

**现状：** 1 主任务 + N 子任务

**问题：**
- 增加系统复杂度
- 增加数据库操作
- 子任务间无数据依赖

**修复方案：** 方案 B - 简化为单任务模式

---

#### 🟡 缺陷8：缺乏上下文连续性

**现状：** 各批次独立分析，AI 对剧情理解是割裂的

**修复方案：**
- 引入 **上下文管理器**
- 自动将上一批次的剧情摘要注入当前 Prompt

---

### 3.4 轻度缺陷 (P3)

#### 🟢 缺陷9：数据模型冗余

`KnowledgeExtractionTaskRecord` 与 `BackgroundTask` 部分重叠

#### 🟢 缺陷10：用户自定义提取未完善

`CUSTOM` 类型在 UI 和后端均未完整实现

#### 🟢 缺陷11：用户无法选择提取类型

**现状：** 当前拆书时自动提取所有类型，用户无法自定义选择

**问题：**
- 用户可能只需要部分提取类型（如只要人物和情节）
- 不需要的类型浪费 Token 成本
- 缺乏灵活性

**修复方案：** 添加提取类型选择对话框（见第六章 UI 设计）

---

### 3.5 提示词缺陷 (P2)

#### 🟡 缺陷12：提示词输出 type 字段不完整

**现状：** 部分提取类型的提示词未指定输出的 `type` 字段值

| 提取类型 | 指定的输出 type | 状态 |
|---------|----------------|------|
| NARRATIVE_STYLE | `NARRATIVE_STYLE` | ✅ |
| WRITING_STYLE | `WRITING_STYLE_FEATURE` | ✅ |
| WORD_USAGE | `WORD_USAGE_FEATURE` | ✅ |
| CORE_CONFLICT | `CORE_CONFLICT_SETTING` | ✅ |
| SUSPENSE_DESIGN | `SUSPENSE_ELEMENT` | ✅ |
| STORY_PACING | `PACING` | ✅ |
| CHARACTER_BUILDING | `CHARACTER` | ✅ |
| WORLDVIEW | **未指定** | ❌ 需修复 |
| GOLDEN_FINGER | **未指定** | ❌ 需修复 |
| RESONANCE | **未指定** | ❌ 需修复 |
| PLEASURE_POINT | **未指定** | ❌ 需修复 |
| EXCITEMENT_POINT | **未指定** | ❌ 需修复 |
| HOT_MEMES | **未指定** | ❌ 需修复 |
| FUNNY_POINTS | **未指定** | ❌ 需修复 |
| CUSTOM | **未指定** | ❌ 需修复 |

**影响：** AI 输出的 type 字段可能不一致，导致前端无法正确归类展示

---

#### 🟡 缺陷13：提示词数量约束不一致

**现状：** 部分类型要求"只生成1个设定"，部分要求"3-5个"，部分无约束

| 提取类型 | 数量约束 | 备注 |
|---------|---------|------|
| NARRATIVE_STYLE | 只生成1个 | ✅ 明确 |
| WRITING_STYLE | 只生成1个 | ✅ 明确 |
| WORD_USAGE | 只生成1个 | ✅ 明确 |
| CORE_CONFLICT | 只生成1个 | ✅ 明确 |
| SUSPENSE_DESIGN | 无约束 | ⚠️ 需补充 |
| STORY_PACING | 无约束 | ⚠️ 需补充 |
| CHARACTER_BUILDING | 每角色1个 | ✅ 明确 |
| WORLDVIEW | 提取多个 | ⚠️ 模糊 |
| GOLDEN_FINGER | 提取所有重要 | ⚠️ 模糊 |
| RESONANCE | 3-5个 | ✅ 明确 |
| PLEASURE_POINT | 3-5个 | ✅ 明确 |
| EXCITEMENT_POINT | 3-5个 | ✅ 明确 |
| HOT_MEMES | 提取所有重要 | ⚠️ 模糊 |
| FUNNY_POINTS | 提取所有重要 | ⚠️ 模糊 |
| CUSTOM | 提取所有有价值 | ⚠️ 模糊 |

---

#### 🟡 缺陷14：CUSTOM 类型提示词过于笼统

**现状：**
```
请从整体角度分析小说，提取用户可能感兴趣的其他创作特点：
- 独特的创意点
- 有意思的设定
- 特殊的表现手法
- 值得借鉴的技巧
```

**问题：** 太泛泛，AI 不知道具体要提取什么

**修复方案：** 

1. 允许用户输入自定义提取需求，作为提示词的一部分
2. **强制结构化输出约束**，确保 CUSTOM 类型输出可控

```java
// CUSTOM 类型的提示词模板（改进版）
private static String getCustomTypePrompt(String userRequirement) {
    return String.format("""
        请根据用户需求分析小说，提取相关信息：
        
        【用户需求】
        %s
        
        【输出要求】
        1. type 字段必须为：CUSTOM
        2. 每个设定必须包含 key_summary 字段（一句话核心概括）
        3. 输出格式：
        {
            "type": "CUSTOM",
            "name": "设定名称（5-15字）",
            "key_summary": "一句话核心概括（20字以内）",
            "description": "详细描述（100-300字）",
            "tags": ["标签1", "标签2"]
        }
        
        【严格约束】
        - 只提取与用户需求相关的内容
        - 每个设定必须有 key_summary 字段
        - 设定数量：3-10个
        """, userRequirement);
}
```

---

## 四、Token 智能分批机制设计

### 4.1 设计原则

1. **基于 Token 而非章节数** - 适配不同模型的上下文窗口
2. **不截断章节** - 保持章节完整性
3. **预留空间** - 为 System Prompt 和输出预留 Token
4. **可配置** - 支持按模型配置调整

### 4.2 Token 预算计算

```java
/**
 * Token 预算配置
 */
public class TokenBudgetConfig {
    // 模型上下文窗口（从模型配置读取）
    private int contextWindow;        // 例：128000
    
    // 预留空间
    private int systemPromptReserve;  // 系统提示词预留，默认 2000
    private int outputReserve;        // 输出预留，默认 4000
    private double safetyMargin;      // 安全边际，默认 0.9
    
    // 计算可用于内容的 Token 数
    public int getContentBudget() {
        return (int) ((contextWindow - systemPromptReserve - outputReserve) * safetyMargin);
    }
}

// 示例：
// GPT-4-128K: (128000 - 2000 - 4000) * 0.9 = 109,800 tokens 可用于内容
// GPT-3.5-16K: (16000 - 2000 - 4000) * 0.9 = 9,000 tokens 可用于内容
```

### 4.3 智能分批算法

```java
/**
 * 基于 Token 的智能分批器
 */
public class TokenBasedBatcher {
    
    private final TokenCounter tokenCounter;
    private final TokenBudgetConfig budgetConfig;
    
    /**
     * 将章节列表分批，确保每批不超过 Token 预算且不截断章节
     */
    public List<ChapterBatch> createBatches(List<Chapter> chapters) {
        List<ChapterBatch> batches = new ArrayList<>();
        int contentBudget = budgetConfig.getContentBudget();
        
        ChapterBatch currentBatch = new ChapterBatch();
        int currentTokens = 0;
        
        for (Chapter chapter : chapters) {
            int chapterTokens = tokenCounter.count(chapter.getContent());
            
            // 单章超过预算：单独一批（会警告）
            if (chapterTokens > contentBudget) {
                if (!currentBatch.isEmpty()) {
                    batches.add(currentBatch);
                    currentBatch = new ChapterBatch();
                    currentTokens = 0;
                }
                log.warn("章节 {} 超过 Token 预算: {} > {}", 
                        chapter.getTitle(), chapterTokens, contentBudget);
                batches.add(new ChapterBatch(List.of(chapter), chapterTokens));
                continue;
            }
            
            // 加入当前章节会超预算：开启新批次
            if (currentTokens + chapterTokens > contentBudget) {
                batches.add(currentBatch);
                currentBatch = new ChapterBatch();
                currentTokens = 0;
            }
            
            // 加入当前批次
            currentBatch.addChapter(chapter);
            currentTokens += chapterTokens;
        }
        
        // 处理最后一批
        if (!currentBatch.isEmpty()) {
            batches.add(currentBatch);
        }
        
        return batches;
    }
}
```

### 4.4 Token 计数策略

```java
public interface TokenCounter {
    int count(String text);
}

// 实现1：简易估算（快速但不精确）
public class SimpleTokenCounter implements TokenCounter {
    @Override
    public int count(String text) {
        // 中文约 1.5 字/token，英文约 4 字符/token
        // 混合文本取平均
        return (int) (text.length() / 1.5);
    }
}

// 实现2：精确计算（使用 tiktoken 或模型 API）
public class TiktokenCounter implements TokenCounter {
    private final Encoding encoding;
    
    @Override
    public int count(String text) {
        return encoding.countTokens(text);
    }
}
```

### 4.5 超长章节兜底处理

**问题：** 极少数情况下，单章可能超过模型 Context Window

**兜底策略：**
```java
/**
 * 超长章节分段器（兜底逻辑）
 */
public class ChapterSegmenter {
    
    /**
     * 将超长章节按段落边界分割
     * 优先在段落结束处切割，保持语义完整性
     */
    public List<ChapterSegment> segmentChapter(Chapter chapter, int maxTokens) {
        String content = chapter.getContent();
        int totalTokens = tokenCounter.count(content);
        
        if (totalTokens <= maxTokens) {
            return List.of(new ChapterSegment(chapter, content, 1, 1));
        }
        
        // 按段落分割
        String[] paragraphs = content.split("\n\n");
        List<ChapterSegment> segments = new ArrayList<>();
        StringBuilder currentSegment = new StringBuilder();
        int currentTokens = 0;
        int segmentIndex = 1;
        
        for (String paragraph : paragraphs) {
            int paragraphTokens = tokenCounter.count(paragraph);
            
            if (currentTokens + paragraphTokens > maxTokens && currentSegment.length() > 0) {
                // 保存当前段
                segments.add(new ChapterSegment(chapter, currentSegment.toString(), 
                        segmentIndex++, -1)); // totalSegments 后续更新
                currentSegment = new StringBuilder();
                currentTokens = 0;
            }
            
            currentSegment.append(paragraph).append("\n\n");
            currentTokens += paragraphTokens;
        }
        
        // 保存最后一段
        if (currentSegment.length() > 0) {
            segments.add(new ChapterSegment(chapter, currentSegment.toString(), 
                    segmentIndex, -1));
        }
        
        // 更新 totalSegments
        int total = segments.size();
        segments.forEach(s -> s.setTotalSegments(total));
        
        log.warn("超长章节 {} 被分割为 {} 段", chapter.getTitle(), total);
        return segments;
    }
}
```

---

## 五、分组 Single-Pass 策略

### 5.1 问题背景

**Output Token 限制风险：**
- Single-Pass 策略要求一次性输出所有类型的提取结果
- 如果同时提取 8 个类型，Output Token 可能超过模型限制（通常 4K-8K）
- 需要设计"分组 Single-Pass"策略平衡 Input 成本和 Output 限制

### 5.2 类型分组策略

将 8 个提取类型分为 **2 个大组**，分两次请求：

| 分组 | 包含类型 | 预估 Output | 说明 |
|------|---------|------------|------|
| **Group A: 设定类** | 文风叙事、人物塑造、小说特点、热梗搞笑 | ~3000 tokens | 偏静态描述 |
| **Group B: 剧情类** | 情节设计、读者情绪、章节大纲 | ~4000 tokens | 偏动态分析 |
| **Group C: 自定义** | CUSTOM | ~1000 tokens | 单独处理 |

### 5.3 执行流程

```java
/**
 * 分组 Single-Pass 提取策略
 */
public class GroupedSinglePassStrategy {
    
    // 类型分组定义
    private static final Map<String, List<KnowledgeExtractionType>> TYPE_GROUPS = Map.of(
        "SETTING_GROUP", List.of(
            NARRATIVE_STYLE, WRITING_STYLE, WORD_USAGE,  // 文风叙事
            CHARACTER_BUILDING,                          // 人物塑造
            WORLDVIEW, GOLDEN_FINGER,                    // 小说特点
            HOT_MEMES, FUNNY_POINTS                      // 热梗搞笑
        ),
        "PLOT_GROUP", List.of(
            CORE_CONFLICT, SUSPENSE_DESIGN, STORY_PACING,  // 情节设计
            RESONANCE, PLEASURE_POINT, EXCITEMENT_POINT,   // 读者情绪
            CHAPTER_OUTLINE                                // 章节大纲
        )
    );
    
    /**
     * 执行分组提取
     * Input Token 只发送 2 次（而非原来的 7-8 次）
     */
    public Mono<Map<String, List<NovelSettingItem>>> extractAll(
            String content, 
            List<KnowledgeExtractionType> selectedTypes) {
        
        // 按用户选择的类型筛选分组
        Map<String, List<KnowledgeExtractionType>> activeGroups = filterGroups(selectedTypes);
        
        // 串行执行各组（避免并发超限）
        return Flux.fromIterable(activeGroups.entrySet())
                .concatMap(entry -> extractGroup(content, entry.getKey(), entry.getValue()))
                .collectMap(GroupResult::getGroupName, GroupResult::getSettings);
    }
}
```

### 5.4 成本对比

| 策略 | Input Token 次数 | Output Token 风险 | 总成本 |
|------|-----------------|------------------|--------|
| 原方案（按类型分组） | 7-8 次 | 低（每次输出少） | **7-8x** |
| 纯 Single-Pass | 1 次 | **高（易超限）** | 1x |
| **分组 Single-Pass** | 2 次 | 中（可控） | **2x** |

### 5.5 模型选择建议

| 模型 | Output 限制 | 是否适合纯 Single-Pass |
|------|------------|----------------------|
| GPT-3.5-turbo | 4K | ❌ 需分组 |
| GPT-4o | 4K | ❌ 需分组 |
| GPT-4o-2024-08-06 | 16K | ✅ 可单次 |
| Claude 3.5 Sonnet | 8K | ⚠️ 勉强可单次 |
| Claude 3 Opus | 4K | ❌ 需分组 |

---

## 六、重构方案

### 方案 A：紧急止血（已完成 + 待完成）

**目标：** 修复阻断级问题，恢复系统可用性

| 任务 | 状态 | 提交 |
|------|------|------|
| 修复 `createProviderByConfigId` 阻塞 | ✅ 完成 | `a48e0e9` |
| 子任务轮询改为事件驱动 | ✅ 完成 | `e30cf1d` |
| 添加拆书任务并发限制 (Semaphore=5) | ✅ 完成 | `e30cf1d` |
| **修复向量化链路** | ⏳ 待做 | - |
| **合并 Prompt（Single-Pass）** | ⏳ 待做 | - |

---

### 方案 B：架构简化 + Token 优化（中期）

**目标：** 简化架构，实现 Token 智能分批

**核心改动：**

1. **取消子任务机制**
   - 主任务内直接串行/有限并发执行 AI 调用
   - 使用 `Flux.concatMap` 或 `Flux.flatMap(..., 2)` 控制

2. **实现 Single-Pass 提取**
   - 一次 LLM 调用提取所有维度
   - Token 成本降低 6-7 倍

3. **实现 Token 智能分批**
   - 移除 `take(10)` 硬编码
   - 基于模型上下文窗口动态分批
   - 保持章节完整性

4. **添加上下文管理器**
   - 滚动摘要注入 Prompt
   - 保持 AI 对剧情理解连续性

5. **添加成本熔断**
   - 实时累计 Token 消耗
   - 超阈值自动熔断

```java
// 简化后的执行流程
private Mono<KnowledgeExtractionResult> extractKnowledge(...) {
    return tokenBatcher.createBatches(chapters)      // 智能分批
            .flatMapSequential(batch ->              // 串行处理批次
                extractBatchWithContext(batch, context)  // 带上下文提取
                    .doOnNext(this::checkCostGuard)      // 成本熔断检查
            )
            .collectList()
            .flatMap(this::aggregateResults)         // 聚合结果
            .flatMap(this::saveWithVectorization);   // 保存 + 向量化
}
```

---

### 方案 C：流水线架构（长期）

**目标：** 支持超大规模小说处理，实现断点续传

```
┌─────────────┐    ┌─────────────┐    ┌─────────────┐    ┌─────────────┐
│  下载 Stage  │───▶│  分析 Stage  │───▶│ 向量化 Stage │───▶│  聚合 Stage  │
│             │    │             │    │             │    │             │
│ 流式下载    │    │ Token 分批   │    │ 并行 Embed   │    │ 合并结果    │
│ 每批 N 章   │    │ Single-Pass │    │ 存入 Chroma  │    │ 存入 Mongo  │
└─────────────┘    └─────────────┘    └─────────────┘    └─────────────┘
      │                  │                  │                  │
      ▼                  ▼                  ▼                  ▼
  ChapterBatch       ExtractResult      VectorResult      FinalResult
      │                  │                  │                  │
      └──────────────────┴──────────────────┴──────────────────┘
                               │
                               ▼
                    ┌──────────────────────┐
                    │     状态持久化        │
                    │ (支持断点续传/重试)   │
                    └──────────────────────┘
```

**特性：**
- 生产者-消费者模型，流式处理
- 每个 Stage 独立重试
- 支持断点续传
- 精细化成本监控

---

## 六、UI/UX 升级规划

### 6.1 提取类型选择对话框（新增功能）

在用户点击"开始拆书"按钮后，弹出提取类型选择对话框：

```
┌────────────────────────────────────────────────────────────────────────────┐
│  选择要提取的内容                                                    [×]   │
├────────────────────────────────────────────────────────────────────────────┤
│                                                                            │
│  📚 基础分析（推荐）                                                       │
│  ┌────────────────────────────────────────────────────────────────────┐   │
│  │ ☑ 文风叙事    包含：叙事方式、文风特点、用词特点                      │   │
│  │ ☑ 人物塑造    提取主要角色的性格、特点、关系                          │   │
│  │ ☑ 章节大纲    生成每章的情节概要                                      │   │
│  └────────────────────────────────────────────────────────────────────┘   │
│                                                                            │
│  📖 情节分析                                                               │
│  ┌────────────────────────────────────────────────────────────────────┐   │
│  │ ☑ 情节设计    核心冲突、悬念设计、故事节奏                            │   │
│  │ ☐ 小说特点    世界观设定、金手指系统                                  │   │
│  └────────────────────────────────────────────────────────────────────┘   │
│                                                                            │
│  🎭 读者体验                                                               │
│  ┌────────────────────────────────────────────────────────────────────┐   │
│  │ ☐ 读者情绪    共鸣点、爽点、嗨点                                      │   │
│  │ ☐ 热梗搞笑    热门梗、搞笑桥段                                        │   │
│  └────────────────────────────────────────────────────────────────────┘   │
│                                                                            │
│  ✏️ 自定义提取                                                             │
│  ┌────────────────────────────────────────────────────────────────────┐   │
│  │ ☐ 启用自定义                                                          │   │
│  │   ┌──────────────────────────────────────────────────────────────┐   │   │
│  │   │ 请输入你想提取的内容，例如：                                    │   │   │
│  │   │ "分析小说中的商业模式和赚钱方法"                                │   │   │
│  │   │ "提取所有的武功招式和修炼功法"                                  │   │   │
│  │   └──────────────────────────────────────────────────────────────┘   │   │
│  └────────────────────────────────────────────────────────────────────┘   │
│                                                                            │
│  ─────────────────────────────────────────────────────────────────────    │
│  💰 预估消耗                                                               │
│     已选 5 个类型 × 约 120 章 ≈ 85,000 Tokens ≈ ¥1.70                      │
│                                                                            │
│  ─────────────────────────────────────────────────────────────────────    │
│                                                                            │
│         [全选]  [推荐配置]  [最小配置]           [取消]  [开始拆书]         │
│                                                                            │
└────────────────────────────────────────────────────────────────────────────┘
```

#### 设计要点

1. **分组展示**
   - 基础分析：文风叙事、人物塑造、章节大纲（推荐默认勾选）
   - 情节分析：情节设计、小说特点
   - 读者体验：读者情绪、热梗搞笑
   - 自定义提取：用户输入自定义需求

2. **预设配置**
   - **推荐配置**：文风叙事 + 人物塑造 + 情节设计 + 章节大纲
   - **最小配置**：仅章节大纲
   - **全选**：所有类型

3. **成本预估（改进版）**
   - 采用 **"阅读费 + 创作费"** 双栏显示，避免用户误解
   - **阅读费（Input）**：固定成本，必须读完全文，与选择类型数量无关
   - **创作费（Output）**：可变成本，随选择类型数量变化
   
   ```
   💰 费用预估
   ├─ 阅读费（固定）：约 120 章 × 3000字 ≈ 240,000 Input Tokens ≈ ¥2.40
   ├─ 创作费（可变）：5 个类型 ≈ 15,000 Output Tokens ≈ ¥0.30
   └─ 总计：约 ¥2.70
   
   💡 提示：减少提取类型主要节省创作费，阅读费基本固定
   ```

4. **自定义提取**
   - 启用后显示文本输入框
   - 用户输入的内容会作为 CUSTOM 类型的提示词补充
   - 示例提示帮助用户理解

#### 后端 API 变更

```java
// 请求参数增加 extractionTypes 字段
public class KnowledgeExtractionRequest {
    private String novelId;
    private String novelUrl;
    
    // 新增：用户选择的提取类型列表
    private List<String> extractionTypes;  // 如 ["NARRATIVE_STYLE", "CHARACTER_BUILDING"]
    
    // 新增：自定义提取需求
    private String customExtractionPrompt;  // 用户输入的自定义需求
}
```

---

### 6.2 用户侧体验优化

#### 流水线可视化 (Pipeline Stepper)

```
┌────────────────────────────────────────────────────────────────┐
│  拆书进度                                                       │
│                                                                │
│  ● 下载中 ──── ○ 分析中 ──── ○ 入库中 ──── ○ 完成              │
│                                                                │
│  📥 正在下载第 45/120 章...                                     │
│  ████████████████░░░░░░░░░░░░░░ 37%                            │
│                                                                │
│  预计剩余时间: 约 8 分钟                                        │
│                                                                │
│  [后台运行]  [取消任务]                                         │
└────────────────────────────────────────────────────────────────┘
```

#### 实时预览 (Real-time Preview)

- 每提取出一个新角色/设定，立即在侧边面板弹出
- "开盲盒"式体验，缓解等待焦虑

#### 断点续传交互

任务失败或暂停时的 UI 处理：

```
┌────────────────────────────────────────────────────────────────┐
│  ⚠️ 任务已暂停                                                  │
│                                                                │
│  📊 已保存进度：67%                                             │
│     - 已下载：80/120 章                                         │
│     - 已分析：设定类（完成）、剧情类（进行中）                    │
│                                                                │
│  💰 已消耗：¥1.80（可从断点继续，无需重新付费）                   │
│                                                                │
│  [继续任务]  [放弃并退款]  [查看已提取内容]                       │
└────────────────────────────────────────────────────────────────┘
```

### 6.3 管理后台升级

#### 全局任务看板

| 指标 | 当前值 | 说明 |
|------|--------|------|
| 并发任务数 | 3/5 | 当前运行 / 最大并发 |
| 排队任务 | 12 | 等待执行的任务 |
| 今日 Token 消耗 | 2.3M | 累计消耗 |
| 今日成本 | ¥45.6 | 累计成本 |

#### 任务详情

- 单任务 Token 账单明细
- Stage 级别执行状态
- 支持单 Stage 重试
- 支持任务熔断/终止

#### 成本审计

- 按用户统计消耗
- 按任务类型统计
- 异常消耗告警

---

## 七、整体重构实施策略

### 7.1 重构原则

**不做零散修补，而是模块化整体重构：**

1. **一次性重构一个完整模块**，而非逐个修 Bug
2. **新旧并行**：新模块开发完成后，通过开关切换，旧模块保留作为回退
3. **前后端协同**：后端 API 变更与前端 UI 同步规划
4. **测试先行**：每个模块重构前先补充测试用例

### 7.2 模块划分

将拆书功能划分为 **5 个可独立重构的模块**：

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                              拆书功能模块架构                                 │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                             │
│  ┌─────────────┐   ┌─────────────┐   ┌─────────────┐   ┌─────────────┐     │
│  │ 模块A       │   │ 模块B       │   │ 模块C       │   │ 模块D       │     │
│  │ 内容获取    │──▶│ AI 提取引擎 │──▶│ 存储入库    │──▶│ 进度与状态  │     │
│  │             │   │             │   │             │   │             │     │
│  │ - 章节下载  │   │ - 分组策略  │   │ - MongoDB   │   │ - 任务管理  │     │
│  │ - Token分批 │   │ - 提示词    │   │ - 向量化    │   │ - 进度推送  │     │
│  │ - 超长兜底  │   │ - 上下文    │   │ - 知识库    │   │ - 成本统计  │     │
│  └─────────────┘   └─────────────┘   └─────────────┘   └─────────────┘     │
│                                                                             │
│  ┌─────────────────────────────────────────────────────────────────────┐   │
│  │ 模块E：用户交互层                                                     │   │
│  │ - 提取类型选择 UI    - 费用预估    - 进度展示    - 断点续传          │   │
│  └─────────────────────────────────────────────────────────────────────┘   │
│                                                                             │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 7.3 重构顺序与依赖关系

```
Phase 1: 基础设施准备
    │
    ├── 1.1 新建 extraction-v2 包结构
    ├── 1.2 定义新接口和数据模型
    └── 1.3 添加功能开关配置
            │
            ▼
Phase 2: 模块B - AI提取引擎重构（核心，成本优化的关键）
    │
    ├── 2.1 重构提示词系统 (KnowledgeExtractionPromptsV2)
    │       - 补全所有 type 字段
    │       - 统一数量约束
    │       - CUSTOM 结构化输出
    │
    ├── 2.2 实现分组 Single-Pass 策略 (GroupedExtractionStrategy)
    │       - 设定类 + 剧情类 双分组
    │       - 输出 Token 控制
    │
    └── 2.3 实现上下文管理器 (ExtractionContextManager)
            - 滚动摘要
            - 跨批次连续性
            │
            ▼
Phase 3: 模块A - 内容获取重构
    │
    ├── 3.1 实现 Token 智能分批器 (TokenBasedBatcher)
    │       - 移除 take(10) 硬编码
    │       - 基于模型上下文窗口
    │
    ├── 3.2 实现超长章节分段器 (ChapterSegmenter)
    │       - 段落边界切割
    │
    └── 3.3 章节流式下载优化
            │
            ▼
Phase 4: 模块C - 存储入库重构
    │
    ├── 4.1 修复向量化链路
    │       - 集成 IndexingService
    │       - 确保 Chroma 入库
    │
    ├── 4.2 知识库存储优化
    │       - 简化数据模型
    │
    └── 4.3 成本记录与审计
            │
            ▼
Phase 5: 模块D - 任务管理重构
    │
    ├── 5.1 简化任务架构（去掉子任务）
    │       - 单任务模式
    │       - 内存进度追踪
    │
    ├── 5.2 成本熔断机制
    │
    └── 5.3 断点续传支持
            │
            ▼
Phase 6: 模块E - 用户交互层
    │
    ├── 6.1 提取类型选择对话框
    ├── 6.2 费用预估（阅读费+创作费）
    ├── 6.3 进度可视化（Pipeline Stepper）
    └── 6.4 断点续传 UI
            │
            ▼
Phase 7: 集成测试与上线
    │
    ├── 7.1 新旧模块对比测试
    ├── 7.2 灰度发布（功能开关）
    └── 7.3 全量切换，下线旧模块
```

### 7.4 详细实施计划

#### Phase 1: 基础设施准备 (1 天)

| 任务 | 说明 | 产出物 |
|------|------|--------|
| 1.1 新建包结构 | `extraction.v2.*` | 目录结构 |
| 1.2 定义新接口 | `ExtractionEngine`, `ContentFetcher`, `StorageService` | 接口文件 |
| 1.3 功能开关 | `extraction.use-v2-engine=false` | 配置项 |
| 1.4 测试框架 | 单元测试基础设施 | 测试基类 |

**产出目录结构：**
```
com.ainovel.server.extraction.v2/
├── engine/
│   ├── ExtractionEngine.java           # 提取引擎接口
│   ├── GroupedExtractionStrategy.java  # 分组策略
│   └── ExtractionContextManager.java   # 上下文管理
├── content/
│   ├── ContentFetcher.java             # 内容获取接口
│   ├── TokenBasedBatcher.java          # Token 分批
│   └── ChapterSegmenter.java           # 超长章节处理
├── storage/
│   ├── KnowledgeStorageService.java    # 存储服务
│   └── VectorizationService.java       # 向量化服务
├── prompt/
│   └── PromptTemplateV2.java           # 新版提示词
├── task/
│   └── ExtractionTaskExecutorV2.java   # 新版任务执行器
└── dto/
    ├── ExtractionRequest.java          # 请求 DTO
    └── ExtractionProgress.java         # 进度 DTO
```

---

#### Phase 2: AI 提取引擎重构 (3-4 天)

**这是成本优化的核心，优先级最高**

| 任务 | 说明 | 预估 |
|------|------|------|
| 2.1 提示词系统重构 | 补全 type、统一约束、CUSTOM 结构化 | 1 天 |
| 2.2 分组 Single-Pass | 设定类+剧情类双分组，2次请求替代7-8次 | 1.5 天 |
| 2.3 上下文管理器 | 滚动摘要，跨批次连续性 | 1 天 |
| 2.4 单元测试 | 提示词测试、分组逻辑测试 | 0.5 天 |

**核心代码设计：**

```java
/**
 * V2 提取引擎 - 分组 Single-Pass 策略
 */
@Service
@ConditionalOnProperty(name = "extraction.use-v2-engine", havingValue = "true")
public class GroupedExtractionEngine implements ExtractionEngine {
    
    // 分组定义
    private static final ExtractionGroup SETTING_GROUP = new ExtractionGroup(
        "SETTING", 
        List.of(NARRATIVE_STYLE, WRITING_STYLE, WORD_USAGE, 
                CHARACTER_BUILDING, WORLDVIEW, GOLDEN_FINGER, 
                HOT_MEMES, FUNNY_POINTS),
        4000  // 预估 Output Token
    );
    
    private static final ExtractionGroup PLOT_GROUP = new ExtractionGroup(
        "PLOT",
        List.of(CORE_CONFLICT, SUSPENSE_DESIGN, STORY_PACING,
                RESONANCE, PLEASURE_POINT, EXCITEMENT_POINT,
                CHAPTER_OUTLINE),
        5000  // 预估 Output Token
    );
    
    @Override
    public Mono<ExtractionResult> extract(ExtractionRequest request) {
        // 1. 根据用户选择筛选激活的分组
        List<ExtractionGroup> activeGroups = filterActiveGroups(request.getSelectedTypes());
        
        // 2. 串行执行各分组（避免并发超限）
        return Flux.fromIterable(activeGroups)
            .concatMap(group -> extractGroup(request.getContent(), group, request.getContext()))
            .collectList()
            .map(this::mergeResults);
    }
    
    private Mono<GroupResult> extractGroup(String content, ExtractionGroup group, 
                                           ExtractionContext context) {
        // 构建分组提示词
        String prompt = promptBuilder.buildGroupPrompt(group, content, context.getSummary());
        
        // 调用 LLM
        return aiProvider.generateContent(prompt)
            .map(response -> parseGroupResult(response, group))
            .doOnNext(result -> context.updateSummary(result));  // 更新滚动摘要
    }
}
```

---

#### Phase 3: 内容获取重构 (2 天)

| 任务 | 说明 | 预估 |
|------|------|------|
| 3.1 Token 智能分批器 | 基于模型上下文窗口动态分批 | 1 天 |
| 3.2 超长章节分段器 | 段落边界切割兜底 | 0.5 天 |
| 3.3 单元测试 | 分批逻辑、边界条件测试 | 0.5 天 |

---

#### Phase 4: 存储入库重构 (1.5 天)

| 任务 | 说明 | 预估 |
|------|------|------|
| 4.1 向量化链路修复 | 集成 IndexingService，确保 Chroma 入库 | 0.5 天 |
| 4.2 知识库存储优化 | 简化数据模型 | 0.5 天 |
| 4.3 成本记录 | Token 消耗审计 | 0.5 天 |

---

#### Phase 5: 任务管理重构 (2 天)

| 任务 | 说明 | 预估 |
|------|------|------|
| 5.1 单任务模式 | 去掉子任务，内存进度追踪 | 1 天 |
| 5.2 成本熔断 | 超阈值自动停止 | 0.5 天 |
| 5.3 断点续传 | 状态持久化与恢复 | 0.5 天 |

---

#### Phase 6: 用户交互层 (3-4 天)

| 任务 | 说明 | 预估 |
|------|------|------|
| 6.1 提取类型选择 UI | Flutter 对话框组件 | 1 天 |
| 6.2 费用预估 | 阅读费+创作费双栏展示 | 0.5 天 |
| 6.3 进度可视化 | Pipeline Stepper 组件 | 1 天 |
| 6.4 断点续传 UI | 继续/放弃选项 | 0.5 天 |
| 6.5 后端 API 适配 | 新增/修改接口 | 1 天 |

---

#### Phase 7: 集成测试与上线 (2-3 天)

| 任务 | 说明 | 预估 |
|------|------|------|
| 7.1 端到端测试 | 完整流程测试 | 1 天 |
| 7.2 新旧对比测试 | 成本、性能、结果对比 | 0.5 天 |
| 7.3 灰度发布 | 功能开关逐步开放 | 0.5 天 |
| 7.4 全量切换 | 下线旧模块 | 0.5 天 |

---

### 7.5 时间线总览

```
Week 1: Phase 1 + Phase 2 (基础设施 + AI提取引擎)
        ├── Day 1: 基础设施准备
        ├── Day 2-3: 提示词系统 + 分组策略
        ├── Day 4: 上下文管理器
        └── Day 5: 单元测试 + Code Review

Week 2: Phase 3 + Phase 4 + Phase 5 (内容获取 + 存储 + 任务管理)
        ├── Day 1-2: Token 分批 + 超长章节
        ├── Day 3: 向量化修复 + 存储优化
        └── Day 4-5: 任务管理重构 + 成本熔断

Week 3: Phase 6 + Phase 7 (用户交互 + 上线)
        ├── Day 1-2: 前端 UI 开发
        ├── Day 3: 后端 API 适配
        ├── Day 4: 集成测试
        └── Day 5: 灰度发布 + 全量切换
```

### 7.6 风险控制

| 风险 | 应对措施 |
|------|---------|
| 新模块 Bug 影响线上 | 功能开关控制，随时回退旧模块 |
| Token 成本预估不准 | 测试环境先跑小样本验证 |
| 进度延期 | Phase 2 是核心，其他可裁剪 |
| 前后端不同步 | API 契约先行，Mock 数据开发 |

### 7.7 最小可行版本 (MVP)

如果时间紧迫，**MVP 只需完成 Phase 1 + Phase 2 + Phase 4.1**：

- ✅ 分组 Single-Pass（成本降 3-4 倍）
- ✅ 向量化修复（RAG 功能恢复）
- ❌ 暂不做 Token 分批（仍用 take(10)）
- ❌ 暂不做 UI 改造

**MVP 预估时间：5-7 天**

---

## 八、相关文件清单

### 后端核心文件

```
AINovalServer/src/main/java/com/ainovel/server/
├── ai/prompts/
│   ├── KnowledgeExtractionPrompts.java         # ⚠️ 提示词需优化
│   └── ChapterOutlineExtractionPrompts.java    # 章节大纲提示词
├── service/
│   ├── KnowledgeExtractionService.java
│   ├── IndexingService.java                    # ⚠️ 需要集成
│   ├── impl/
│   │   ├── KnowledgeExtractionServiceImpl.java
│   │   └── IndexingServiceImpl.java
│   └── ai/
│       ├── strategy/
│       │   └── KnowledgeExtractionStrategy.java # ⚠️ 需要修改
│       └── observability/
│           └── LLMTraceService.java            # 保持联动
├── task/
│   ├── executor/
│   │   ├── KnowledgeExtractionTaskExecutor.java     # ⚠️ 需要修改
│   │   └── KnowledgeExtractionGroupTaskExecutor.java
│   └── service/
│       └── SubTaskCompletionService.java       # ✅ 已添加
└── domain/model/
    ├── KnowledgeExtractionType.java
    └── NovelKnowledgeBase.java
```

### 前端核心文件

```
AINoval/lib/
├── screens/knowledge_base/
│   ├── knowledge_base_detail_screen.dart       # 8 个 Tab 展示
│   ├── extraction_progress_dialog.dart         # ⚠️ 需要升级
│   ├── knowledge_extraction_task_management_page.dart
│   └── widgets/
│       ├── knowledge_extraction_import_dialog.dart  # 现有导入对话框
│       └── extraction_type_selector_dialog.dart     # 🆕 待新增：提取类型选择
├── blocs/knowledge_base/
│   └── knowledge_base_bloc.dart
└── models/
    └── knowledge_base_models.dart
```

---

## 九、监控与告警

### 建议添加的监控指标

1. **Token 消耗指标**
   - 单任务 Token 消耗
   - 累计 Token 消耗（按小时/天）
   - Token 消耗异常告警

2. **成本指标**
   - 单任务成本
   - 累计成本
   - 成本熔断触发次数

3. **向量化指标**
   - 向量入库成功率
   - 向量存储延迟
   - Chroma 存储容量

4. **任务指标**
   - 任务成功率
   - 平均执行时间
   - 队列积压数

---

## 十、回滚方案

1. **功能开关控制**
   - 通过配置开关控制新旧逻辑切换
   - 问题发生时快速回退

2. **版本兼容**
   - 新任务使用新类型标识
   - 旧任务继续使用旧逻辑

3. **数据迁移**
   - 增量迁移，不影响存量数据
   - 支持双写双读过渡期

---

## 十一、代码审查补充意见

> 以下内容来自 2025-11-30 代码审查，对原方案进行补充和细化。

### 11.1 关于"分组 Single-Pass"策略的风险补充

文档提出将 8 个类型分为 2 组（设定类 + 剧情类），但**当前代码已经实现了按组提取**（见 `KnowledgeExtractionGroupTaskExecutor`），问题在于：
- 当前分组粒度太细（7-8 组），每组只有 1-3 个类型
- **当前分组定义位置**：`KnowledgeExtractionTaskExecutor.getGroupName()` 方法

```java
// 当前分组定义（需要在重构时修改）
private String getGroupName(KnowledgeExtractionType type) {
    return switch (type) {
        case NARRATIVE_STYLE, WRITING_STYLE, WORD_USAGE -> "文风叙事";
        case CORE_CONFLICT, SUSPENSE_DESIGN, STORY_PACING -> "情节设计";
        case CHARACTER_BUILDING -> "人物塑造";
        case WORLDVIEW, GOLDEN_FINGER -> "小说特点";
        case RESONANCE, PLEASURE_POINT, EXCITEMENT_POINT -> "读者情绪";
        case HOT_MEMES, FUNNY_POINTS -> "热梗搞笑点";
        case CUSTOM -> "用户自定义";
        case CHAPTER_OUTLINE -> "章节大纲";
    };
}
```

**建议**：重构时将分组合并为 2 个大组，修改此方法即可。

---

### 11.2 提示词 `truncateContent` 废弃方法问题

**现状：**
```java
// KnowledgeExtractionPrompts.java
@Deprecated
private static String truncateContent(String content, int maxLength) {
    return content;  // 已取消截断，直接返回完整内容
}
```

虽然标记 `@Deprecated`，但 `getGroupUserPrompt()` 仍在调用它。

**建议：**
- 方案 A：彻底移除该方法，直接使用 `content`
- 方案 B：在重构时实现真正的 Token 分批逻辑，替换此方法

---

### 11.3 缺失的风险点：Output Token 解析失败

**问题：** 当 AI 输出的 JSON 格式错误时，`parseKnowledgeJsonForGroup()` 会返回空列表，**静默丢失数据**。

**现状代码：**
```java
.onErrorResume(error -> {
    log.error("知识组提取失败: types={}, error={}", ...);
    return Mono.just(Collections.emptyList());  // ← 静默丢失
});
```

**建议：**
1. 添加 JSON 修复重试机制（代码中有 `JsonRepairUtils`，但未充分利用）
2. 记录解析失败的原始响应到日志或数据库，便于排查
3. 在任务结果中标记"部分提取失败"状态

---

### 11.4 关于 Phase 2 优先级的建议

文档将"AI 提取引擎重构"放在 Phase 2，建议调整：

| 原优先级 | 建议调整 | 理由 |
|---------|---------|------|
| Phase 2.1 提示词修复 | **提前到 Phase 1.5** | 低风险、高收益，可独立执行 |
| Phase 4.1 向量化修复 | **✅ 已完成** | 一行代码修复，恢复 RAG 功能 |
| Phase 3 Token 分批 | 保持 | 依赖架构设计 |

**提示词修复可独立先行**：补全 `type` 字段、统一数量约束是低风险改动，可快速止血。

---

### 11.5 断点续传的技术难点

文档提到"断点续传"，但未说明具体实现方案：

**需要解决的问题：**
1. 如何持久化"已提取的类型"状态？
2. 如何避免重复消耗 Token？
3. 如何恢复上下文（滚动摘要）？

**建议方案：**
在 `KnowledgeExtractionTaskRecord` 中增加字段：

```java
public class KnowledgeExtractionTaskRecord {
    // ... 现有字段 ...
    
    // 新增：断点续传支持
    private Set<String> completedGroups;      // 已完成的分组名称
    private String lastContextSummary;        // 上一批次的上下文摘要
    private Integer lastProcessedChapterIndex; // 最后处理的章节索引
    private Map<String, Long> groupTokenUsage; // 各分组的 Token 消耗
}
```

---

### 11.6 成本预估公式修正

文档中的费用预估公式需要修正：

**原公式（不准确）：**
```
阅读费（固定）：约 120 章 × 3000字 ≈ 240,000 Input Tokens
```

**修正后公式：**
```
阅读费 = 总字数 × 分组数 × Input 单价

示例（当前架构，7-8 组）：
- 总字数：36 万字（120 章 × 3000 字）
- 分组数：7
- Input Token：36 万 × 7 ÷ 1.5 ≈ 168 万 tokens

示例（优化后，2 组）：
- 分组数：2
- Input Token：36 万 × 2 ÷ 1.5 ≈ 48 万 tokens
- 节省：约 71%
```

**建议**：在 UI 费用预估中明确显示"当前分组数"，让用户理解成本构成。

---

## 十二、更新日志

| 日期 | 内容 | 提交 |
|------|------|------|
| 2025-11-30 | 创建文档，完成架构分析 | - |
| 2025-11-30 | 修复 `createProviderByConfigId` 阻塞 | `a48e0e9` |
| 2025-11-30 | 事件驱动 + 并发限制 | `e30cf1d` |
| 2025-11-30 | 整合专家点评，补充 Token 分批、UI 规划、系统联动 | - |
| 2025-11-30 | 新增提示词缺陷分析、提取类型选择 UI 设计、自定义提取功能规划 | - |
| 2025-11-30 | 整合架构师审查意见：分组 Single-Pass 策略、Output Token 限制处理、超长章节兜底、费用双栏展示、断点续传 UI、CUSTOM 结构化输出 | - |
| 2025-11-30 | **重构实施策略大改版**：从零散修补改为模块化整体重构，7 个 Phase、3 周时间线、MVP 方案 | - |
| 2025-11-30 | **✅ 修复向量化链路断裂**：`KnowledgeExtractionTaskExecutor` 添加 `IndexingService` 依赖，Scene 保存后自动索引到 Chroma | 待提交 |
| 2025-11-30 | 新增代码审查补充意见：分组定义位置、truncateContent 废弃方法、JSON 解析失败风险、断点续传技术难点、费用预估公式修正 | - |
